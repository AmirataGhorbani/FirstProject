{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import pickle\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from d_u import load_CIFAR10\n",
    "import structures\n",
    "from amirata_functions import *\n",
    "from pylab import rcParams\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from CNN_class import CNN_SC\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "config_gpu = tf.ConfigProto()\n",
    "config_gpu.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data,aux_data = get_CIFAR10_data(\"../datasets/cifar-10-batches-py\")\n",
    "mean_image=data[\"mean_image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN_points(object):\n",
    "    \n",
    "    def __init__(self,  num_centers, centers_dist, network_name,\n",
    "                 num_conv_layers, num_forward_layers, input_shape,\n",
    "                 num_classes, path,kernel_sizes, hidden_sizes, \n",
    "                 pool_sizes, dims, learning_rate = 0.001, \n",
    "                 padding = \"SAME\", initialize=False,dropout = 1, \n",
    "                 reject_cost = 0.2, activation=\"relu\",reg = 0,\n",
    "                 dynamic = False, batch_norm=True, loss_coeff=0):\n",
    "        self.network_name = network_name\n",
    "        self.centers_dist=centers_dist\n",
    "        self.num_forward_layers = num_forward_layers\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.batch_norm = batch_norm\n",
    "        self.input_shape = input_shape \n",
    "        #FIXIT: assumption is images are square\n",
    "        self.dims = dims\n",
    "        self.loss_coeff=loss_coeff\n",
    "        self.padding = padding\n",
    "        self.learning_rate = learning_rate\n",
    "        self.pool_sizes = pool_sizes\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.num_classed = num_classes\n",
    "        self.dropout = dropout\n",
    "        self.dynamic = dynamic\n",
    "        self.num_classes = num_classes\n",
    "        self.path = path\n",
    "        self.reg = reg\n",
    "        self.flatten_size = self.flatten_size_calculator()\n",
    "        self.Pdic = self.make_Pdic()\n",
    "        self.initialize = initialize\n",
    "        self.num_centers=num_centers\n",
    "        self.dropout_ph = tf.placeholder(tf.float32)\n",
    "        self.input_ph = tf.placeholder\\\n",
    "        (dtype= tf.float32,shape= [None, self.input_shape[0],self.\\\n",
    "                                   input_shape[1],self.input_shape[2]])\n",
    "        self.output_ph = tf.placeholder(dtype= tf.int32, shape= [None,])\n",
    "        self.is_training_ph = tf.placeholder(tf.bool)\n",
    "        self.activation = self.get_activation(activation)\n",
    "        self.build(self.input_ph)\n",
    "        \n",
    "    def make_Pdic(self):\n",
    "        \n",
    "        Pdic = {}\n",
    "        \n",
    "        Pdic[\"W\"] = tf.get_variable\\\n",
    "        (\"W\", shape = [self.hidden_sizes[self.num_forward_layers-1]\\\n",
    "                       ,self.num_classes],initializer=\\\n",
    "         tf.contrib.layers.xavier_initializer())\n",
    "        Pdic[\"b\"] = tf.get_variable(\"b\", shape=[self.num_classes],\\\n",
    "                                    initializer=tf.zeros_initializer())\n",
    "        \n",
    "        self.sum_weights = tf.reduce_sum( Pdic[\"W\"]**2)\n",
    "        \n",
    "        flat_length = self.flatten_size[self.num_conv_layers-1]\n",
    "        \n",
    "        for number in range(self.num_conv_layers):\n",
    "            Pdic[\"K{}\".format(number)] =  tf.get_variable\\\n",
    "            (\"K{}\".format(number),shape=[self.kernel_sizes[number]\\\n",
    "                                         ,self.kernel_sizes[number]\\\n",
    "                                         ,(number==0)*self.input_shape[-1]\\\n",
    "                                         + (number>0)*self.dims[number-1],\\\n",
    "                                         self.dims[number]],initializer=\\\n",
    "             tf.contrib.layers.xavier_initializer())\n",
    "            Pdic[\"z{}\".format(number)] = tf.get_variable\\\n",
    "            (\"z{}\".format(number), shape = [self.dims[number]],\\\n",
    "             initializer=tf.zeros_initializer())\n",
    "        \n",
    "        for layer in range(self.num_forward_layers):\n",
    "            \n",
    "            Pdic[\"W{}\".format(layer)] = tf.get_variable\\\n",
    "            (\"W{}\".format(layer),shape=[flat_length*(layer==0)+\\\n",
    "                                        self.hidden_sizes[layer-1]*(layer>0)\\\n",
    "                                        ,self.hidden_sizes[layer]],\n",
    "                                 initializer=\\\n",
    "             tf.contrib.layers.xavier_initializer())\n",
    "            self.sum_weights += tf.reduce_sum( Pdic[\"W{}\".format(layer)]**2)\n",
    "            Pdic[\"b{}\".format(layer)] = tf.get_variable\\\n",
    "            (\"b{}\".format(layer),shape=[self.hidden_sizes[layer]]\\\n",
    "             , initializer=tf.zeros_initializer())\n",
    "        return Pdic\n",
    "        \n",
    "\n",
    "\n",
    "    def get_activation(self, name):\n",
    "        if name == \"relu\":\n",
    "            return tf.nn.relu\n",
    "        if name == \"tanh\":\n",
    "            return tf.nn.tanh\n",
    "        if name == \"sigmoid\":\n",
    "            return tf.sigmoid\n",
    "    \n",
    "    \n",
    "    def conv_layer(self, number, feed):\n",
    "        \n",
    "        conv = tf.nn.conv2d(input=feed, filter=self.Pdic[\"K{}\".format(number)]\\\n",
    "                            , padding=\"SAME\", strides=[1,1,1,1])\n",
    "        out_convv =\\\n",
    "        self.activation(conv + self.Pdic[\"z{}\".format(number)])\n",
    "        if self.batch_norm:\n",
    "            out_conv = tf.layers.batch_normalization\\\n",
    "            (out_convv,axis=-1,training=self.is_training_ph)\n",
    "        else:\n",
    "            out_conv = out_convv\n",
    "        pool = tf.layers.max_pooling2d\\\n",
    "        (inputs=out_conv, pool_size=self.pool_sizes[number],\\\n",
    "         strides=self.pool_sizes[number])\n",
    "        return pool\n",
    "    \n",
    "    def fc_layer(self, layer, feed):\n",
    "        out = tf.matmul(feed,self.Pdic[\"W{}\".format(layer)])+\\\n",
    "        self.Pdic[\"b{}\".format(layer)]\n",
    "        out_relued = tf.nn.dropout(self.activation(out), \n",
    "                                   self.dropout_ph)\n",
    "        return out_relued\n",
    "    \n",
    "    def flatten_size_calculator(self):\n",
    "        if self.num_conv_layers:\n",
    "            output = np.zeros(self.num_conv_layers)\n",
    "            temp = self.input_shape[0]//self.pool_sizes[0]\n",
    "            output[0] = temp*temp*self.dims[0]\n",
    "            for n in range(1,self.num_conv_layers):\n",
    "                temp = temp//self.pool_sizes[n]\n",
    "                output[n] = temp*temp*self.dims[n]\n",
    "        else:\n",
    "            output = np.array([self.input_shape[0]*self.input_shape[1]*\\\n",
    "            self.input_shape[2]])\n",
    "        return output.astype(int)\n",
    "    \n",
    "        \n",
    "    def build(self, feed):\n",
    "        # FIXIT: assumption is all convolutions are square\n",
    "        out = feed\n",
    "        for layer in range(self.num_conv_layers):\n",
    "            out = self.conv_layer(layer, out)\n",
    "        flat_length = self.flatten_size[self.num_conv_layers-1]\n",
    "        out = tf.reshape(out, shape=[-1, flat_length])\n",
    "        for layer in range(self.num_forward_layers):\n",
    "            out = self.fc_layer(layer,out)\n",
    "        self.hidden = out\n",
    "        self.dic = {}\n",
    "        \n",
    "            \n",
    "    def get_batches(self, training_data, batch_size, validation_data):   \n",
    "        Xs = training_data[0]\n",
    "        Ys = training_data[1]\n",
    "        mask = np.random.permutation(len(Ys))\n",
    "        Xs = Xs[mask]\n",
    "        Ys = Ys[mask]\n",
    "        X_batches = [Xs[k:k + batch_size] for k in range(0, len(Xs)\\\n",
    "                                                         , batch_size)]\n",
    "        Y_batches = [Ys[k:k + batch_size] for k in range(0, len(Ys)\\\n",
    "                                                         , batch_size)]\n",
    "        return X_batches, Y_batches, validation_data[0], validation_data[1]\n",
    "\n",
    "\n",
    "    def do_epoch(self, sess, epoch, X_batches, Y_batches, X_val, Y_val,\n",
    "                 X_train, Y_train, verbose):\n",
    "        avg_cost = 0\n",
    "        mskn = np.random.choice(range(X_train.shape[0]),len(X_val),replace=False)\n",
    "        x_train = X_train[mskn]\n",
    "        y_train = Y_train[mskn]\n",
    "        for X_batch, Y_batch in zip(X_batches, Y_batches):\n",
    "            sess.run(self.dic[\"optmz_h\"],\n",
    "                     feed_dict={self.input_ph:X_batch,\n",
    "                                self.output_ph:Y_batch,\n",
    "                                self.is_training_ph:True,\n",
    "                               self.dropout_ph:self.dropout})\n",
    "        val_h = sess.run(self.hidden,\n",
    "                         feed_dict={self.input_ph:X_val,\n",
    "                                    self.is_training_ph:False,\n",
    "                                    self.dropout_ph:1})\n",
    "        val_cost = sess.run(self.dic[\"cost_h\"],\n",
    "                            feed_dict={self.input_ph:X_val,\n",
    "                                       self.output_ph:Y_val,\n",
    "                                       self.is_training_ph:False,\n",
    "                                       self.dropout_ph:1})\n",
    "        acc, rate = self.evaluate(val_h,Y_val)\n",
    "        tr_h = sess.run(self.hidden,\n",
    "                        feed_dict={self.input_ph:x_train,\n",
    "                                   self.is_training_ph:False,\n",
    "                                   self.dropout_ph:1})\n",
    "        tr_cost = sess.run(self.dic[\"cost_h\"],\n",
    "                           feed_dict={self.input_ph:x_train,\n",
    "                                      self.output_ph:y_train,\n",
    "                                      self.is_training_ph:False,\n",
    "                                      self.dropout_ph:1})\n",
    "        acc_train, _ = self.evaluate(tr_h,y_train)\n",
    "        if verbose:\n",
    "            print(\"Epoch:{}\".format(epoch))\n",
    "            print(\"Val/Train Accuracy:{}/{}\".format(acc,acc_train))\n",
    "            print(\"Val/Train Cost:{}/{}\".format(val_cost,tr_cost))\n",
    "            if rate<1:\n",
    "                print(\"rate:{}\").format(rate)\n",
    "        return acc\n",
    "    \n",
    "    def tradeoff(self,sess, X_val, Y_val):\n",
    "        self.acc_hist = []\n",
    "        self.rate_hist = []\n",
    "        self.thresh_list = []\n",
    "        val_h = sess.run(self.hidden,\\\n",
    "                         feed_dict={self.input_ph:X_val,\\\n",
    "                                    self.is_training_ph:False,\n",
    "                                    self.dropout_ph:1})\n",
    "        r=0.\n",
    "        thresh = 1e5*1.\n",
    "        while(r<0.95):\n",
    "            thresh /= 1.001\n",
    "            self.thresh_list.append(thresh)\n",
    "            a,r = self.evaluate(val_h,Y_val,thresh)\n",
    "            r = 1-r\n",
    "            self.acc_hist.append(a)\n",
    "            self.rate_hist.append(r)\n",
    "#                 print(thresh,a,r)\n",
    "          \n",
    "    def give_back_centers(self,X_train,y_train, num_centers, \n",
    "                          sess=None):\n",
    "        if sess==None:\n",
    "            sess=get_session()\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess,self.path)  \n",
    "        new_centers=np.zeros((self.num_classes,num_centers,\n",
    "                              self.hidden_sizes[-1]))\n",
    "        for i in range(self.num_classes):\n",
    "            args = np.where(y_train==i)[0]\n",
    "            args_center = np.random.choice(args,num_centers,\n",
    "                                           replace=False)\n",
    "            in_center=X_train[args_center]\n",
    "            new_centers[i]=sess.run(self.hidden,\n",
    "                                    feed_dict={self.input_ph:in_center,\n",
    "                                              self.dropout_ph:1,\n",
    "                                              self.is_training_ph:False})\n",
    "        return new_centers\n",
    "    \n",
    "    def optimize(self, training_data, validation_data,\n",
    "                 save, load , reg= 0, epochs=10,batch_size= 200, \n",
    "                 tradeoff=False, verbose=True, save_always=False, \n",
    "                 loss_coeff=0, centers=None):\n",
    "        \n",
    "        if np.size(centers)>1:\n",
    "            centers_init=centers\n",
    "        else:\n",
    "            centers_init=self.centers_dist*\\\n",
    "            np.random.random((self.num_classes,self.num_centers,\n",
    "                             self.hidden_sizes[-1]))\n",
    "        self.centers_var=tf.cast(tf.Variable(centers_init),\n",
    "                                 tf.float32)   \n",
    "        labels = tf.cast(tf.one_hot(self.output_ph,self.num_classes),\\\n",
    "                         tf.float32)\n",
    "        self.distances = tf_l2_distance_expert(self.hidden,\n",
    "                                               self.centers_var)\n",
    "        self.min_distance = tf.reduce_min(self.distances,axis=-1)\n",
    "        self.which_center = tf.argmin(self.distances, axis=-1)\n",
    "        self.dic[\"cost_h\"] =\\\n",
    "        tf.reduce_mean(tf.reduce_sum(self.min_distance * labels,\n",
    "                                     axis=1))-self.loss_coeff*\\\n",
    "        tf.reduce_sum(tf_self_distances(self.centers_var))\\\n",
    "        +0.5*self.reg*(self.sum_weights)\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):                                                                       \n",
    "            self.dic[\"optmz_h\"]= tf.train.AdamOptimizer\\\n",
    "            (self.learning_rate).minimize(self.dic[\"cost_h\"])\n",
    "            \n",
    "        X_batches, Y_batches, X_val, Y_val = \\\n",
    "        self.get_batches(training_data, batch_size, validation_data)\n",
    "        X_train = training_data[0]\n",
    "        Y_train = training_data[1]\n",
    "        saver = tf.train.Saver()\n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "            \n",
    "        with tf.Session(config=config_gpu) as sess:\n",
    "            sess.run(init)\n",
    "            print(sess.run(tf_self_distances(self.centers_var)))\n",
    "#             new_centers=self.give_back_centers(X_train,Y_train,\n",
    "#                                               self.num_centers,sess)\n",
    "#             self.centers_var=tf.Variable(new_centers)\n",
    "#             sess.run(tf.variables_initializer([self.centers_var]))\n",
    "#             print(sess.run(tf_self_distances(self.centers_var)))\n",
    "            if load:\n",
    "                saver.restore(sess,self.path)\n",
    "            self.centers,val_h = sess.run([self.centers_var,self.hidden],\\\n",
    "                             feed_dict={self.input_ph:X_val,\\\n",
    "                                        self.is_training_ph:False,\n",
    "                                        self.dropout_ph:1})\n",
    "            best_val, _ = self.evaluate(val_h,Y_val)\n",
    "            if verbose:\n",
    "                print(\"validation accuracy before starting\",best_val)\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                print(np.linalg.norm\\\n",
    "                      (self.centers-sess.run(self.centers_var)))\n",
    "                self.centers=sess.run(self.centers_var)\n",
    "                acc = self.do_epoch(sess, epoch, X_batches, Y_batches,\n",
    "                                    X_val, Y_val,X_train,\n",
    "                                    Y_train, verbose)\n",
    "                if acc>=best_val or save_always: #FIXIT\n",
    "                    best_val = acc\n",
    "                    saved_path = saver.save(sess, self.path)\n",
    "                    if verbose and not save_always:\n",
    "                        print(\"New best!\")\n",
    "            self.best_val = best_val \n",
    "            print(\"Best val accuracy:\",self.best_val)\n",
    "            saver.restore(sess,self.path)\n",
    "            if tradeoff:\n",
    "                self.tradeoff(sess, X_val, Y_val)\n",
    "\n",
    "    def predict(self, hidden):\n",
    "        index = -1\n",
    "        counter = 0.\n",
    "        correct = 0.\n",
    "        out = np.zeros(hidden.shape[0])\n",
    "        diff_tensor =\\\n",
    "        tf.minimum(tf_l2_distance_expert(tf.constant(hidden)\n",
    "                                         ,self.centers_var),axis=-1)\n",
    "        diff=sess.run(diff_tensor)\n",
    "        out = np.argmin(diff,axis=1)\n",
    "        return out\n",
    "    \n",
    "    def adversary(self, feed, mean_image, epsilon, true_label, \n",
    "                  mode=\"BIM\",sess=None,max_iter=30,verbose=False,\n",
    "                  alpha=1):\n",
    "        feed=np.expand_dims(feed,axis=0)\n",
    "        true_label=[true_label]\n",
    "        if sess==None:\n",
    "            sess=get_session()\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess,self.path)\n",
    "        net_dists = sess.run(self.min_distance,\n",
    "                             feed_dict={self.input_ph:feed,\n",
    "                                       self.dropout_ph:1.,\n",
    "                                       self.is_training_ph:False})\n",
    "        \n",
    "        net_label= np.argmin(net_dists,1)\n",
    "        fake_label=np.argmax(net_dists,1)\n",
    "        if net_label!=true_label:\n",
    "            if verbose:\n",
    "                print(\"Network is already misclassifying\")\n",
    "            return \n",
    "        adv = feed\n",
    "        iters=0\n",
    "        cont=True\n",
    "        changed_label=False\n",
    "        while(cont and iters<max_iter):\n",
    "            iters += 1\n",
    "            if mode==\"BIM\":\n",
    "                gradient = sess.run(tf.gradients(self.dic[\"cost_h\"],\n",
    "                                        self.input_ph)[0],\n",
    "                                    feed_dict={self.input_ph:adv,\n",
    "                                   self.is_training_ph:False,\n",
    "                                   self.output_ph:true_label,\n",
    "                                   self.dropout_ph:1})\n",
    "                adv_temp = adv + alpha*np.sign(gradient)\n",
    "            if mode==\"ILLCM\":\n",
    "                gradient = sess.run(tf.gradients(self.dic[\"cost_h\"],\n",
    "                                        self.input_ph)[0],\n",
    "                                    feed_dict={self.input_ph:adv,\n",
    "                                   self.is_training_ph:False,\n",
    "                                   self.output_ph:fake_label,\n",
    "                                   self.dropout_ph:1})\n",
    "                adv_temp = adv - alpha*np.sign(gradient)\n",
    "            adv_temp=np.maximum(np.maximum(feed-epsilon,adv_temp),\n",
    "                             -mean_image)\n",
    "            \n",
    "            adv=np.minimum(np.minimum(feed+epsilon,adv_temp),\n",
    "                           255-mean_image)\n",
    "            \n",
    "            out_adv = sess.run(self.min_distance,\n",
    "                             feed_dict={self.input_ph:adv,\n",
    "                                       self.dropout_ph:1.,\n",
    "                                       self.is_training_ph:False})\n",
    "            confidence = np.min(out_adv,1)\n",
    "            new_label = np.argmin(out_adv,1)\n",
    "            if verbose:\n",
    "                print(\"True label:\",true_label,\"New label:\",\n",
    "                     new_label,\"Confidence:\", confidence)\n",
    "            if new_label!=true_label:\n",
    "                changed_label=True\n",
    "            if changed_label and confidence<1000:\n",
    "                cont=False\n",
    "        return adv, changed_label, confidence\n",
    "            \n",
    "    def evaluate(self, hidden, y, thresh=1e100):  \n",
    "        correct = 0.\n",
    "        diff = np.min(l2_distance_expert(hidden,self.centers),\n",
    "                          axis=-1)\n",
    "        passed = np.min(diff,1)<thresh\n",
    "        passed_num = np.sum(passed)\n",
    "        correct = np.argmin(diff,1) == y     \n",
    "        return np.sum(correct*passed)*1./passed_num,\\\n",
    "    passed_num*1./y.shape[0]\n",
    "    \n",
    "    def feedforward(self, feed, sess=None):\n",
    "        if sess==None:\n",
    "            sess=get_session()\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess,self.path)  \n",
    "        output = sess.run\\\n",
    "        (self.hidden, {self.input_ph: feed,\n",
    "                       self.is_training_ph : False,\n",
    "                       self.dropout_ph:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.68319e+07\n",
      "INFO:tensorflow:Restoring parameters from saved_networks/points_3\n",
      "validation accuracy before starting 0.5155\n",
      "0.0\n",
      "Epoch:0\n",
      "Val/Train Accuracy:0.5175/0.9915\n",
      "Val/Train Cost:-8572942336.0/-8572945920.0\n",
      "New best!\n",
      "3.4113\n",
      "Epoch:1\n",
      "Val/Train Accuracy:0.52/0.9935\n",
      "Val/Train Cost:-8624424960.0/-8624429056.0\n",
      "New best!\n",
      "3.42159\n",
      "Epoch:2\n",
      "Val/Train Accuracy:0.5105/0.993\n",
      "Val/Train Cost:-8676209664.0/-8676215808.0\n",
      "3.43162\n",
      "Epoch:3\n",
      "Val/Train Accuracy:0.516/0.9955\n",
      "Val/Train Cost:-8728298496.0/-8728303616.0\n",
      "3.4414\n",
      "Epoch:4\n",
      "Val/Train Accuracy:0.52/0.998\n",
      "Val/Train Cost:-8780691456.0/-8780694528.0\n",
      "New best!\n",
      "3.45094\n",
      "Epoch:5\n",
      "Val/Train Accuracy:0.52/0.998\n",
      "Val/Train Cost:-8833386496.0/-8833393664.0\n",
      "New best!\n",
      "3.46026\n",
      "Epoch:6\n",
      "Val/Train Accuracy:0.5065/0.993\n",
      "Val/Train Cost:-8886387712.0/-8886393856.0\n",
      "3.46935\n",
      "Epoch:7\n",
      "Val/Train Accuracy:0.505/0.9975\n",
      "Val/Train Cost:-8939696128.0/-8939700224.0\n",
      "3.47824\n",
      "Epoch:8\n",
      "Val/Train Accuracy:0.5085/0.9975\n",
      "Val/Train Cost:-8993310720.0/-8993316864.0\n",
      "3.48693\n",
      "Epoch:9\n",
      "Val/Train Accuracy:0.513/0.999\n",
      "Val/Train Cost:-9047233536.0/-9047237632.0\n",
      "3.49542\n",
      "Epoch:10\n",
      "Val/Train Accuracy:0.502/0.9975\n",
      "Val/Train Cost:-9101460480.0/-9101466624.0\n",
      "3.50373\n",
      "Epoch:11\n",
      "Val/Train Accuracy:0.4995/0.996\n",
      "Val/Train Cost:-9155997696.0/-9156003840.0\n",
      "3.51186\n",
      "Epoch:12\n",
      "Val/Train Accuracy:0.4785/0.996\n",
      "Val/Train Cost:-9210847232.0/-9210853376.0\n",
      "3.51982\n",
      "Epoch:13\n",
      "Val/Train Accuracy:0.4585/0.9815\n",
      "Val/Train Cost:-9266003968.0/-9266008064.0\n",
      "3.5276\n",
      "Epoch:14\n",
      "Val/Train Accuracy:0.4275/0.9575\n",
      "Val/Train Cost:-9321472000.0/-9321477120.0\n",
      "3.53523\n",
      "Epoch:15\n",
      "Val/Train Accuracy:0.504/0.995\n",
      "Val/Train Cost:-9377249280.0/-9377255424.0\n",
      "3.5427\n",
      "Epoch:16\n",
      "Val/Train Accuracy:0.447/0.946\n",
      "Val/Train Cost:-9433338880.0/-9433345024.0\n",
      "3.55001\n",
      "Epoch:17\n",
      "Val/Train Accuracy:0.442/0.9515\n",
      "Val/Train Cost:-9489741824.0/-9489745920.0\n",
      "3.55718\n",
      "Epoch:18\n",
      "Val/Train Accuracy:0.46/0.979\n",
      "Val/Train Cost:-9546458112.0/-9546464256.0\n",
      "3.5642\n",
      "Epoch:19\n",
      "Val/Train Accuracy:0.4735/0.9995\n",
      "Val/Train Cost:-9603487744.0/-9603493888.0\n",
      "3.57109\n",
      "Epoch:20\n",
      "Val/Train Accuracy:0.5205/0.999\n",
      "Val/Train Cost:-9660828672.0/-9660834816.0\n",
      "New best!\n",
      "3.57784\n",
      "Epoch:21\n",
      "Val/Train Accuracy:0.522/1.0\n",
      "Val/Train Cost:-9718482944.0/-9718488064.0\n",
      "New best!\n",
      "3.58445\n",
      "Epoch:22\n",
      "Val/Train Accuracy:0.498/0.9995\n",
      "Val/Train Cost:-9776449536.0/-9776456704.0\n",
      "3.59094\n",
      "Epoch:23\n",
      "Val/Train Accuracy:0.491/1.0\n",
      "Val/Train Cost:-9834733568.0/-9834739712.0\n",
      "3.5973\n",
      "Epoch:24\n",
      "Val/Train Accuracy:0.499/0.9995\n",
      "Val/Train Cost:-9893331968.0/-9893339136.0\n",
      "3.60354\n",
      "Epoch:25\n",
      "Val/Train Accuracy:0.5125/1.0\n",
      "Val/Train Cost:-9952245760.0/-9952252928.0\n",
      "3.60966\n",
      "Epoch:26\n",
      "Val/Train Accuracy:0.495/1.0\n",
      "Val/Train Cost:-10011472896.0/-10011481088.0\n",
      "3.61566\n",
      "Epoch:27\n",
      "Val/Train Accuracy:0.5185/1.0\n",
      "Val/Train Cost:-10071017472.0/-10071023616.0\n",
      "3.62155\n",
      "Epoch:28\n",
      "Val/Train Accuracy:0.4905/0.9985\n",
      "Val/Train Cost:-10130875392.0/-10130881536.0\n",
      "3.62733\n",
      "Epoch:29\n",
      "Val/Train Accuracy:0.4735/1.0\n",
      "Val/Train Cost:-10191049728.0/-10191058944.0\n",
      "3.633\n",
      "Epoch:30\n",
      "Val/Train Accuracy:0.4955/1.0\n",
      "Val/Train Cost:-10251543552.0/-10251550720.0\n",
      "3.63857\n",
      "Epoch:31\n",
      "Val/Train Accuracy:0.5195/1.0\n",
      "Val/Train Cost:-10312349696.0/-10312356864.0\n",
      "3.64403\n",
      "Epoch:32\n",
      "Val/Train Accuracy:0.5205/1.0\n",
      "Val/Train Cost:-10373475328.0/-10373482496.0\n",
      "3.64939\n",
      "Epoch:33\n",
      "Val/Train Accuracy:0.5195/1.0\n",
      "Val/Train Cost:-10434916352.0/-10434926592.0\n",
      "3.65465\n",
      "Epoch:34\n",
      "Val/Train Accuracy:0.494/1.0\n",
      "Val/Train Cost:-10496678912.0/-10496686080.0\n",
      "3.65981\n",
      "Epoch:35\n",
      "Val/Train Accuracy:0.523/1.0\n",
      "Val/Train Cost:-10558753792.0/-10558760960.0\n",
      "New best!\n",
      "3.66488\n",
      "Epoch:36\n",
      "Val/Train Accuracy:0.5165/1.0\n",
      "Val/Train Cost:-10621146112.0/-10621154304.0\n",
      "3.66986\n",
      "Epoch:37\n",
      "Val/Train Accuracy:0.5145/1.0\n",
      "Val/Train Cost:-10683857920.0/-10683865088.0\n",
      "3.67474\n",
      "Epoch:38\n",
      "Val/Train Accuracy:0.528/1.0\n",
      "Val/Train Cost:-10746886144.0/-10746892288.0\n",
      "New best!\n",
      "3.67953\n",
      "Epoch:39\n",
      "Val/Train Accuracy:0.529/1.0\n",
      "Val/Train Cost:-10810231808.0/-10810238976.0\n",
      "New best!\n",
      "Best val accuracy: 0.529\n",
      "INFO:tensorflow:Restoring parameters from saved_networks/points_3\n"
     ]
    }
   ],
   "source": [
    "training_data = (data[\"X_train\"][:2000],data[\"y_train\"][:2000])\n",
    "validation_data1 = (aux_data[\"X_val1\"],aux_data[\"y_val1\"])\n",
    "tf.reset_default_graph()\n",
    "network_F = CNN_points(num_centers = 10, centers_dist=10,\n",
    "                        network_name=\"network1\",num_conv_layers=3,\n",
    "                        num_forward_layers=1,input_shape=[32,32,3], \n",
    "                        reg = 1e-2,num_classes=10,kernel_sizes=[5,5,5],\n",
    "                        hidden_sizes=[1024], pool_sizes=[2,2,2], \n",
    "                        padding = \"same\",path =\"saved_networks/points_3\",\n",
    "                        loss_coeff=100,dims=[64,128,256], \n",
    "                        learning_rate = 1e-3, \n",
    "                        batch_norm = True, dropout = 1)\n",
    "network_F.optimize(training_data, validation_data1, \n",
    "                   epochs=40, load = True, save = True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_networks/1C_3L_T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_networks/1C_3L_T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: [1] New label: [1] Confidence: [ 6151.04003906]\n",
      "True label: [1] New label: [1] Confidence: [ 6583.11328125]\n",
      "True label: [1] New label: [1] Confidence: [ 7061.31835938]\n",
      "True label: [1] New label: [1] Confidence: [ 7446.57519531]\n",
      "True label: [1] New label: [1] Confidence: [ 7455.21875]\n",
      "True label: [1] New label: [1] Confidence: [ 7574.50390625]\n",
      "True label: [1] New label: [1] Confidence: [ 7478.99902344]\n",
      "True label: [1] New label: [1] Confidence: [ 7720.94238281]\n",
      "True label: [1] New label: [1] Confidence: [ 7795.15234375]\n",
      "True label: [1] New label: [1] Confidence: [ 7908.30859375]\n",
      "True label: [1] New label: [1] Confidence: [ 7944.12109375]\n",
      "True label: [1] New label: [1] Confidence: [ 8011.90136719]\n",
      "True label: [1] New label: [1] Confidence: [ 8052.42089844]\n",
      "True label: [1] New label: [1] Confidence: [ 8135.328125]\n",
      "True label: [1] New label: [1] Confidence: [ 8145.66992188]\n",
      "True label: [1] New label: [1] Confidence: [ 8191.0390625]\n",
      "True label: [1] New label: [1] Confidence: [ 8179.06835938]\n",
      "True label: [1] New label: [1] Confidence: [ 8216.91308594]\n",
      "True label: [1] New label: [1] Confidence: [ 8209.88476562]\n",
      "True label: [1] New label: [1] Confidence: [ 8238.25292969]\n",
      "True label: [1] New label: [1] Confidence: [ 8218.86035156]\n",
      "True label: [1] New label: [1] Confidence: [ 8239.7578125]\n",
      "True label: [1] New label: [1] Confidence: [ 8233.13085938]\n",
      "True label: [1] New label: [9] Confidence: [ 8238.00488281]\n",
      "True label: [1] New label: [1] Confidence: [ 8238.68554688]\n",
      "True label: [1] New label: [9] Confidence: [ 8232.91796875]\n",
      "True label: [1] New label: [9] Confidence: [ 8226.46777344]\n",
      "True label: [1] New label: [9] Confidence: [ 8215.06347656]\n",
      "True label: [1] New label: [9] Confidence: [ 8217.80761719]\n",
      "True label: [1] New label: [9] Confidence: [ 8212.171875]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[[ -6.38991250e+01,  -6.71391000e+01,  -9.95475250e+01],\n",
       "          [ -6.12976000e+01,  -6.94913250e+01,  -9.98008750e+01],\n",
       "          [ -6.52357000e+01,  -6.83168250e+01,  -1.01545350e+02],\n",
       "          ..., \n",
       "          [ -6.22537500e+01,  -6.03587250e+01,  -8.73814250e+01],\n",
       "          [ -5.15653500e+01,  -6.07493000e+01,  -8.69332000e+01],\n",
       "          [ -3.63482750e+01,  -5.55151000e+01,  -8.48278500e+01]],\n",
       " \n",
       "         [[ -6.32286750e+01,  -6.63075500e+01,  -1.00293350e+02],\n",
       "          [ -6.44595500e+01,  -6.74519500e+01,  -1.05370175e+02],\n",
       "          [ -6.43390250e+01,  -7.11772250e+01,  -1.00005450e+02],\n",
       "          ..., \n",
       "          [ -5.22552250e+01,  -5.92118500e+01,  -8.98616750e+01],\n",
       "          [ -4.35204500e+01,  -5.26138250e+01,  -8.84553250e+01],\n",
       "          [ -4.83135500e+01,  -5.34037250e+01,  -9.53843250e+01]],\n",
       " \n",
       "         [[ -6.38231750e+01,  -6.76227750e+01,  -9.21649000e+01],\n",
       "          [ -6.18138250e+01,  -5.54700250e+01,  -9.29213000e+01],\n",
       "          [ -7.06145500e+01,  -6.50787750e+01,  -1.05412900e+02],\n",
       "          ..., \n",
       "          [ -6.03619750e+01,  -6.19957250e+01,  -9.42062250e+01],\n",
       "          [ -5.07593750e+01,  -6.45833250e+01,  -9.09833500e+01],\n",
       "          [ -5.17586000e+01,  -5.35901000e+01,  -8.91575000e+01]],\n",
       " \n",
       "         ..., \n",
       "         [[ -1.06378000e+01,  -1.40216000e+01,  -5.13512500e+00],\n",
       "          [ -2.06981000e+01,  -2.98493250e+01,  -2.08296500e+01],\n",
       "          [ -7.69726250e+01,  -7.98691750e+01,  -6.97434000e+01],\n",
       "          ..., \n",
       "          [ -1.03425300e+02,  -1.02130850e+02,  -9.00021750e+01],\n",
       "          [ -5.38562250e+01,  -4.58604750e+01,  -3.28808000e+01],\n",
       "          [ -6.67182500e+00,  -5.96230000e+00,  -2.22447500e+00]],\n",
       " \n",
       "         [[ -1.81604250e+01,  -2.14615000e+01,  -2.06461500e+01],\n",
       "          [ -3.15580250e+01,  -3.06695500e+01,  -2.17085750e+01],\n",
       "          [ -4.83495250e+01,  -5.12667750e+01,  -5.01866750e+01],\n",
       "          ..., \n",
       "          [ -6.57454000e+01,  -6.45455000e+01,  -5.24496000e+01],\n",
       "          [ -4.68197500e+01,  -5.38382000e+01,  -3.69046500e+01],\n",
       "          [ -4.11803750e+01,  -4.04307500e+01,  -2.07609750e+01]],\n",
       " \n",
       "         [[ -5.81630000e+00,  -7.01910000e+00,   5.67225000e-01],\n",
       "          [ -5.65262500e+00,  -8.70222500e+00,   5.49750000e-02],\n",
       "          [ -6.93160000e+00,  -8.83295000e+00,  -9.52625000e-01],\n",
       "          ..., \n",
       "          [ -3.00484750e+01,  -2.19265500e+01,  -1.80417250e+01],\n",
       "          [ -2.48111500e+01,  -2.38269500e+01,  -1.21040000e+01],\n",
       "          [ -2.28637250e+01,  -2.40354500e+01,  -1.25743000e+01]]]]),\n",
       " True,\n",
       " array([ 8212.171875], dtype=float32))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_F.adversary(aux_data[\"X_val2\"][3],mean_image,4,\n",
    "                    aux_data[\"y_val2\"][3],mode=\"ILLCM\",\n",
    "                   verbose=True,alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network_F.tradeoff(sess,aux_data[\"X_val2\"][1:1000],\n",
    "                   aux_data[\"y_val2\"][1:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CNN_centers' object has no attribute 'acc_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-a40a85cb477c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork_F\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'CNN_centers' object has no attribute 'acc_list'"
     ]
    }
   ],
   "source": [
    "network_F.acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f08c4a790b8>]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkSinIhARiXIqAhGRKPf/Ad0sYf7WBEWAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f08c4a9f5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(network_F.rate_hist,network_F.acc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

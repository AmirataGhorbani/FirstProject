{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from d_u import load_CIFAR10\n",
    "import structures\n",
    "def save_object(object, filename):\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(object,output,pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_object(object, fielname):\n",
    "    with open(fielname, 'rb') as input:\n",
    "        object = pickle.load(input)\n",
    "\n",
    "def entropy(feed):\n",
    "    return np.sum(-feed*np.log(feed),axis=-1)\n",
    "\n",
    "def tf_entropy(feed):\n",
    "    return tf.reduce_sum(-feed*tf.log(feed),axis=-1)\n",
    "    \n",
    "def accuracy_entropy(output,labels,thresh):\n",
    "    correct = 0.\n",
    "    wrong = 0.\n",
    "    reject = entropy(output)>thresh\n",
    "    reject = reject.astype(\"float\")\n",
    "    correct = (np.argmax(output,axis=1)==labels)\n",
    "\n",
    "    correct = correct.astype(\"float\")\n",
    "    acc = np.sum(correct * (1-reject))/np.sum(1-reject)\n",
    "    rej = np.mean(reject)\n",
    "    if rej<1:\n",
    "        #print(\"acc:{} rej:{}\",acc,rej)\n",
    "        return (acc,rej)\n",
    "         \n",
    "        \n",
    "def accuracy_probability(output,labels,thresh):\n",
    "    correct = 0.\n",
    "    wrong = 0.\n",
    "    reject = np.max(output,axis=1)<thresh\n",
    "    reject = reject.astype(\"float\")\n",
    "    correct = (np.argmax(output,axis=1)==labels)\n",
    "\n",
    "    correct = correct.astype(\"float\")\n",
    "    acc = np.sum(correct * (1-reject))/np.sum(1-reject)\n",
    "    rej = np.mean(reject)\n",
    "    if rej<1:\n",
    "        #print(\"acc:{} rej:{}\",acc,rej)\n",
    "        return (acc,rej)\n",
    "    \n",
    "config_gpu = tf.ConfigProto()\n",
    "config_gpu.gpu_options.allow_growth = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train data shape: ', (40000, 32, 32, 3))\n",
      "('Train labels shape: ', (40000,))\n",
      "('Validation data shape: ', (10000, 32, 32, 3))\n",
      "('Validation labels shape: ', (10000,))\n",
      "('Test data shape: ', (10000, 32, 32, 3))\n",
      "('Test labels shape: ', (10000,))\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=40000, num_validation=10000, num_test=10000):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = '../../../../../lfs/1/amiratag/datasets/cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "#     X_train /= 255\n",
    "#     X_val /= 255\n",
    "#     X_test /= 255\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, mean_image\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, mean_image = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "X_train1 = X_train[:25000]\n",
    "y_train1 = y_train[:25000]\n",
    "X_val1 = X_val[:2000]\n",
    "y_val1 = y_val[:2000]\n",
    "X_train2 = X_train[25000:]\n",
    "y_train2 = y_train[25000:]\n",
    "X_val2 = X_val[5000:]\n",
    "y_val2 = y_val[5000:]\n",
    "X_train.shape\n",
    "training_data = (X_train,y_train)\n",
    "training_data1 = (X_train1, y_train1)\n",
    "training_data2 = (X_train2, y_train2)\n",
    "validation_data = (X_val,y_val)\n",
    "validation_data1 = (X_val1,y_val1)\n",
    "validation_data2 = (X_val2,y_val2)\n",
    "test_data = (X_test, y_test)\n",
    "train_mask = np.argsort(y_train)\n",
    "val_mask = np.argsort(y_val2)\n",
    "y_train_sorted = y_train[train_mask].copy()\n",
    "y_val_sorted = y_val2[val_mask].copy()\n",
    "X_train_sorted = X_train[train_mask].copy()\n",
    "X_val_sorted = X_val2[val_mask].copy()\n",
    "X_train_0 = X_train_sorted[:3900]\n",
    "X_train_1 = X_train_sorted[4000:7900]\n",
    "X_train_2 = X_train_sorted[8000:11900]\n",
    "X_train_3 = X_train_sorted[12000:15900]\n",
    "X_train_4 = X_train_sorted[16100:20000]\n",
    "X_train_5 = X_train_sorted[20050:23950]\n",
    "X_train_6 = X_train_sorted[24000:27900]\n",
    "X_train_7 = X_train_sorted[28100:32000]\n",
    "X_train_8 = X_train_sorted[32100:36000]\n",
    "X_train_9 = X_train_sorted[36100:]\n",
    "X_tr = [X_train_0,X_train_1,X_train_2,X_train_3,X_train_4,X_train_5,X_train_6,X_train_7,X_train_8,X_train_9]\n",
    "X_val_0 = X_val_sorted[:400]\n",
    "X_val_1 = X_val_sorted[500:900]\n",
    "X_val_2 = X_val_sorted[1000:1400]\n",
    "X_val_3 = X_val_sorted[1500:1900]\n",
    "X_val_4 = X_val_sorted[2000:2400]\n",
    "X_val_5 = X_val_sorted[2500:2900]\n",
    "X_val_6 = X_val_sorted[3000:3400]\n",
    "X_val_7 = X_val_sorted[3500:3900]\n",
    "X_val_8 = X_val_sorted[4000:4400]\n",
    "X_val_9 = X_val_sorted[4500:4900]\n",
    "X_v = [X_val_0,X_val_1,X_val_2,X_val_3,X_val_4,X_val_5,X_val_6,X_val_7,X_val_8,X_val_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sphere_distortion(r,N,n,NET,w=32,h=32,c=3,hidden_size=1024,verbose=False,X_val=None):\n",
    "    sess=get_session()\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess,NET.path)  \n",
    "    cond_nums=[]\n",
    "    dists = np.zeros(n)\n",
    "    points = np.zeros((n,w,h,c))\n",
    "    points_mapped = np.zeros((n,hidden_size))\n",
    "    for i in range(N):\n",
    "        if verbose:\n",
    "            if N>10:\n",
    "                if i%(N//10)==0:\n",
    "                    print(i)\n",
    "            else:\n",
    "                print(i)\n",
    "        if X_val==None:\n",
    "            point = 255*np.random.random((1,w,h,c))-mean_image\n",
    "        else:\n",
    "            point = np.expand_dims(X_val[np.random.choice(X_val.shape[0])],0)\n",
    "        point_mapped = NET.scores(point,sess)\n",
    "        if n<2000:\n",
    "            points = point + r*unitpoint(n,32,32,3)\n",
    "            points_mapped = NET.scores(points,sess)\n",
    "            dists = np.linalg.norm(points_mapped-point_mapped,axis=1)\n",
    "        else:\n",
    "            for ctr in range(n//2000):\n",
    "                points[ctr*2000:(ctr+1)*2000] = point + r*unitpoint(2000,w,h,c)\n",
    "                points_mapped[ctr*2000:(ctr+1)*2000] = NET.scores(points[ctr*2000:(ctr+1)*2000],sess)\n",
    "                dists[ctr*2000:(ctr+1)*2000] = sess.run(tf.norm(tf.constant(points_mapped[ctr*2000:(ctr+1)*2000])-\n",
    "                                                                       tf.cast(tf.constant(point_mapped),tf.float64),1))\n",
    "\n",
    "        cond_nums.append(max(dists)/min(dists))\n",
    "    cond_nums = np.array(cond_nums)\n",
    "    weights = 100*np.ones_like(cond_nums)/len(cond_nums)\n",
    "    rcParams['figure.figsize'] = 10, 10\n",
    "    plt.hist(cond_nums,20,weights=weights)\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"%\")\n",
    "    print(np.mean(cond_nums),np.var(cond_nums))\n",
    "    return cond_nums\n",
    "\n",
    "def histogram_plotter(data,bins,xlabel=\"\"):\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    from pylab import rcParams\n",
    "    weights = 100*np.ones_like(data)/len(data)\n",
    "    plt.hist(data,bins,weights=weights)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"%\")\n",
    "\n",
    "        \n",
    "def PolMut(x, eta, prob,up,down):\n",
    "    up = up*1.\n",
    "    down = down*1.\n",
    "    eta = eta*1.\n",
    "    mask = (np.random.random(x.shape)<prob).astype(\"float\")\n",
    "    changed = mask*x\n",
    "    unchanged = (1-mask)*x\n",
    "    delta1 = x*mask/(up-down)\n",
    "    delta2 = (1-x)*mask/(up-down)\n",
    "    r = np.random.random(x.shape)\n",
    "    r_mask = (r<0.5).astype(\"float\")\n",
    "    r_mask1 = r_mask * mask\n",
    "    r_mask2 = (1-r_mask) * mask\n",
    "    r1 = r * r_mask1\n",
    "    r2 = r * r_mask2\n",
    "    q1 = (2*r1+(1-2*r1)*r_mask1*(mask*(1-delta1))**(eta+1))\n",
    "    q2 = (2*(1-r2)+2*(r2-0.5)*r_mask2*(mask*(1-delta2))**(eta+1))\n",
    "    d = (q1**(1./(eta+1))-1) * r_mask1 + (1-q2**(1./(eta+1))) * r_mask2\n",
    "    result = unchanged + changed+d*(up-down)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_session():\n",
    "    \"\"\"Create a session that dynamically allocates memory.\"\"\"\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    return session\n",
    "\n",
    "def to_percent(y, position):\n",
    "    # Ignore the passed in position. This has the effect of scaling the default\n",
    "    # tick locations.\n",
    "    s = str(100 * y)\n",
    "\n",
    "    # The percent symbol needs escaping in latex\n",
    "    if matplotlib.rcParams['text.usetex'] is True:\n",
    "        return s + r'$\\%$'\n",
    "    else:\n",
    "        return s + '%'\n",
    "    \n",
    "    \n",
    "def cluster_points(X, mu):\n",
    "    clusters  = {}\n",
    "    for x in X:\n",
    "        bestmukey = min([(i[0], np.linalg.norm(x-mu[i[0]])) \\\n",
    "                    for i in enumerate(mu)], key=lambda t:t[1])[0]\n",
    "        try:\n",
    "            clusters[bestmukey].append(x)\n",
    "        except KeyError:\n",
    "            clusters[bestmukey] = [x]\n",
    "    return clusters\n",
    " \n",
    "    \n",
    "def reevaluate_centers(mu, clusters):\n",
    "    newmu = []\n",
    "    keys = sorted(clusters.keys())\n",
    "    for k in keys:\n",
    "        newmu.append(np.mean(clusters[k], axis = 0))\n",
    "    return newmu\n",
    " \n",
    "    \n",
    "def has_converged(mu, oldmu):\n",
    "    return (set([tuple(a) for a in mu]) == set([tuple(a) for a in oldmu]))\n",
    " \n",
    "    \n",
    "def find_centers(X, K):\n",
    "    # Initialize to K random centers\n",
    "    oldmu = random.sample(X, K)\n",
    "    mu = random.sample(X, K)\n",
    "    while not has_converged(mu, oldmu):\n",
    "        oldmu = mu\n",
    "        # Assign all points in X to clusters\n",
    "        clusters = cluster_points(X, mu)\n",
    "        # Reevaluate centers\n",
    "        mu = reevaluate_centers(oldmu, clusters)\n",
    "    return(mu, clusters)\n",
    "\n",
    "def unitpoint(N,w,h,c):\n",
    "    a = np.random.normal(size=(N,w*h*c))\n",
    "    b = np.expand_dims(np.sqrt(np.sum(a**2,1)),1)\n",
    "    return np.reshape(a/b,[N,w,h,c])\n",
    "  \n",
    "    \n",
    "def random_triangle(N,w,h,c,r,mean_image,a=None):\n",
    "    if a==None:\n",
    "        a = 255*np.random.random((N,w,h,c))-mean_image\n",
    "        a = np.reshape(a,[N,-1])\n",
    "    base = np.reshape(r*unitpoint(N,w,h,c),[N,-1])\n",
    "    base = base/np.expand_dims(np.linalg.norm(base,axis=1),-1)\n",
    "    b = a + r*base\n",
    "    orthog = np.reshape(unitpoint(N,w,h,c),[N,-1])\n",
    "    orthog = orthog - np.expand_dims(np.diagonal(np.inner(orthog,base)),-1) * base\n",
    "    orthog = orthog/np.expand_dims(np.linalg.norm(orthog,axis=1),-1)\n",
    "    orthog = orthog * r * np.sqrt(3)/2\n",
    "    c = a + r*base/2 + orthog\n",
    "    return np.reshape(a,[N,w,h,-1]),np.reshape(b,[N,w,h,-1]),np.reshape(c,[N,w,h,-1])\n",
    "\n",
    "\n",
    "def l2_distance(a,b):\n",
    "    norm_a = np.sum(a**2,1,keepdims=True)\n",
    "    norm_b = np.sum((b.T)**2,0,keepdims=True)\n",
    "    output = -2*a.dot(b.T)\n",
    "    output += norm_a\n",
    "    output += norm_b\n",
    "    return np.sqrt(output)\n",
    "\n",
    "def tf_l2_distance(a,b):\n",
    "    norm_a = tf.reduce_sum(a**2,axis=1,keep_dims=True)\n",
    "    norm_b = tf.reduce_sum(tf.transpose(b)**2,axis=0,keep_dims=True)\n",
    "    output = -2*tf.matmul(a,tf.transpose(b))\n",
    "    output += norm_a\n",
    "    output += norm_b\n",
    "    return tf.sqrt(output)\n",
    "\n",
    "def condition_number_dist(sess,r,NET,iters,num_points=32*32*3,w=32,h=32,c=3,mean_image=mean_image):\n",
    "    for i in range(iters):\n",
    "        if i%100==0:\n",
    "            print(i)\n",
    "        point = 255*np.random.random((1,w,h,c))-mean_image\n",
    "        points = point + r*unitpoint(num_points,w,h,c)\n",
    "        point_mapped = NET.scores(point,sess)\n",
    "        points_mapped = NET.scores(points,sess)\n",
    "        dists = np.linalg.norm(points_mapped-point_mapped,axis=1)\n",
    "        cond_nums.append(max(dists)/min(dists))\n",
    "    return cond_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sphere_distortion(r,N,n,NET,w=32,h=32,c=3,hidden_size=1024,verbose=False,X_val=None):\n",
    "    sess=get_session()\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess,NET.path)  \n",
    "    cond_nums=[]\n",
    "    dists = np.zeros(n)\n",
    "    points = np.zeros((n,w,h,c))\n",
    "    points_mapped = np.zeros((n,hidden_size))\n",
    "    for i in range(N):\n",
    "        if verbose:\n",
    "            if N>10:\n",
    "                if i%(N//10)==0:\n",
    "                    print(i)\n",
    "            else:\n",
    "                print(i)\n",
    "        if X_val==None:\n",
    "            point = 255*np.random.random((1,w,h,c))-mean_image\n",
    "        else:\n",
    "            point = np.expand_dims(X_val[np.random.choice(X_val.shape[0])],0)\n",
    "        point_mapped = NET.scores(point,sess)\n",
    "        if n<2000:\n",
    "            points = point + r*unitpoint(n,32,32,3)\n",
    "            points_mapped = NET.scores(points,sess)\n",
    "            dists = np.linalg.norm(points_mapped-point_mapped,axis=1)\n",
    "        else:\n",
    "            for ctr in range(n//2000):\n",
    "                points[ctr*2000:(ctr+1)*2000] = point + r*unitpoint(2000,w,h,c)\n",
    "                points_mapped[ctr*2000:(ctr+1)*2000] = NET.scores(points[ctr*2000:(ctr+1)*2000],sess)\n",
    "                dists[ctr*2000:(ctr+1)*2000] = sess.run(tf.norm(tf.constant(points_mapped[ctr*2000:(ctr+1)*2000])-\n",
    "                                                                       tf.cast(tf.constant(point_mapped),tf.float64),1))\n",
    "\n",
    "        cond_nums.append(max(dists)/min(dists))\n",
    "    cond_nums = np.array(cond_nums)\n",
    "    weights = 100*np.ones_like(cond_nums)/len(cond_nums)\n",
    "    rcParams['figure.figsize'] = 10, 10\n",
    "    plt.hist(cond_nums,20,weights=weights)\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"%\")\n",
    "    print(np.mean(cond_nums),np.var(cond_nums))\n",
    "    return cond_nums\n",
    "\n",
    "def histogram_plotter(data,bins,xlabel=\"\"):\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    from pylab import rcParams\n",
    "    weights = 100*np.ones_like(data)/len(data)\n",
    "    plt.hist(data,bins,weights=weights)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"%\")\n",
    "\n",
    "        \n",
    "def PolMut(x, eta, prob,up,down):\n",
    "    up = up*1.\n",
    "    down = down*1.\n",
    "    eta = eta*1.\n",
    "    mask = (np.random.random(x.shape)<prob).astype(\"float\")\n",
    "    changed = mask*x\n",
    "    unchanged = (1-mask)*x\n",
    "    delta1 = x*mask/(up-down)\n",
    "    delta2 = (1-x)*mask/(up-down)\n",
    "    r = np.random.random(x.shape)\n",
    "    r_mask = (r<0.5).astype(\"float\")\n",
    "    r_mask1 = r_mask * mask\n",
    "    r_mask2 = (1-r_mask) * mask\n",
    "    r1 = r * r_mask1\n",
    "    r2 = r * r_mask2\n",
    "    q1 = (2*r1+(1-2*r1)*r_mask1*(mask*(1-delta1))**(eta+1))\n",
    "    q2 = (2*(1-r2)+2*(r2-0.5)*r_mask2*(mask*(1-delta2))**(eta+1))\n",
    "    d = (q1**(1./(eta+1))-1) * r_mask1 + (1-q2**(1./(eta+1))) * r_mask2\n",
    "    result = unchanged + changed+d*(up-down)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_session():\n",
    "    \"\"\"Create a session that dynamically allocates memory.\"\"\"\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    return session\n",
    "\n",
    "def to_percent(y, position):\n",
    "    # Ignore the passed in position. This has the effect of scaling the default\n",
    "    # tick locations.\n",
    "    s = str(100 * y)\n",
    "\n",
    "    # The percent symbol needs escaping in latex\n",
    "    if matplotlib.rcParams['text.usetex'] is True:\n",
    "        return s + r'$\\%$'\n",
    "    else:\n",
    "        return s + '%'\n",
    "    \n",
    "    \n",
    "def cluster_points(X, mu):\n",
    "    clusters  = {}\n",
    "    for x in X:\n",
    "        bestmukey = min([(i[0], np.linalg.norm(x-mu[i[0]])) \\\n",
    "                    for i in enumerate(mu)], key=lambda t:t[1])[0]\n",
    "        try:\n",
    "            clusters[bestmukey].append(x)\n",
    "        except KeyError:\n",
    "            clusters[bestmukey] = [x]\n",
    "    return clusters\n",
    " \n",
    "    \n",
    "def reevaluate_centers(mu, clusters):\n",
    "    newmu = []\n",
    "    keys = sorted(clusters.keys())\n",
    "    for k in keys:\n",
    "        newmu.append(np.mean(clusters[k], axis = 0))\n",
    "    return newmu\n",
    " \n",
    "    \n",
    "def has_converged(mu, oldmu):\n",
    "    return (set([tuple(a) for a in mu]) == set([tuple(a) for a in oldmu]))\n",
    " \n",
    "    \n",
    "def find_centers(X, K):\n",
    "    # Initialize to K random centers\n",
    "    oldmu = random.sample(X, K)\n",
    "    mu = random.sample(X, K)\n",
    "    while not has_converged(mu, oldmu):\n",
    "        oldmu = mu\n",
    "        # Assign all points in X to clusters\n",
    "        clusters = cluster_points(X, mu)\n",
    "        # Reevaluate centers\n",
    "        mu = reevaluate_centers(oldmu, clusters)\n",
    "    return(mu, clusters)\n",
    "\n",
    "def unitpoint(N,w,h,c):\n",
    "    a = np.random.normal(size=(N,w*h*c))\n",
    "    b = np.expand_dims(np.sqrt(np.sum(a**2,1)),1)\n",
    "    return np.reshape(a/b,[N,w,h,c])\n",
    "  \n",
    "    \n",
    "def random_triangle(N,w,h,c,r,mean_image,a=None):\n",
    "    if a==None:\n",
    "        a = 255*np.random.random((N,w,h,c))-mean_image\n",
    "        a = np.reshape(a,[N,-1])\n",
    "    base = np.reshape(r*unitpoint(N,w,h,c),[N,-1])\n",
    "    base = base/np.expand_dims(np.linalg.norm(base,axis=1),-1)\n",
    "    b = a + r*base\n",
    "    orthog = np.reshape(unitpoint(N,w,h,c),[N,-1])\n",
    "    orthog = orthog - np.expand_dims(np.diagonal(np.inner(orthog,base)),-1) * base\n",
    "    orthog = orthog/np.expand_dims(np.linalg.norm(orthog,axis=1),-1)\n",
    "    orthog = orthog * r * np.sqrt(3)/2\n",
    "    c = a + r*base/2 + orthog\n",
    "    return np.reshape(a,[N,w,h,-1]),np.reshape(b,[N,w,h,-1]),np.reshape(c,[N,w,h,-1])\n",
    "\n",
    "\n",
    "def l2_distance(a,b):\n",
    "    norm_a = np.sum(a**2,1,keepdims=True)\n",
    "    norm_b = np.sum((b.T)**2,0,keepdims=True)\n",
    "    output = -2*a.dot(b.T)\n",
    "    output += norm_a\n",
    "    output += norm_b\n",
    "    return np.sqrt(output)\n",
    "\n",
    "def tf_l2_distance(a,b):\n",
    "    norm_a = tf.reduce_sum(a**2,axis=1,keep_dims=True)\n",
    "    norm_b = tf.reduce_sum(tf.transpose(b)**2,axis=0,keep_dims=True)\n",
    "    output = -2*tf.matmul(a,tf.transpose(b))\n",
    "    output += norm_a\n",
    "    output += norm_b\n",
    "    return tf.sqrt(output)\n",
    "\n",
    "def condition_number_dist(sess,r,NET,iters,num_points=32*32*3,w=32,h=32,c=3,mean_image=mean_image):\n",
    "    for i in range(iters):\n",
    "        if i%100==0:\n",
    "            print(i)\n",
    "        point = 255*np.random.random((1,w,h,c))-mean_image\n",
    "        points = point + r*unitpoint(num_points,w,h,c)\n",
    "        point_mapped = NET.scores(point,sess)\n",
    "        points_mapped = NET.scores(points,sess)\n",
    "        dists = np.linalg.norm(points_mapped-point_mapped,axis=1)\n",
    "        cond_nums.append(max(dists)/min(dists))\n",
    "    return cond_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_SC(object):\n",
    "    \n",
    "    def __init__(self,  centers, new_loss, network_name, num_conv_layers, num_forward_layers, input_shape, num_classes, path, \n",
    "                 kernel_sizes, hidden_sizes, pool_sizes, dims, learning_rate = 0.001, padding = \"SAME\", initialize=False,\n",
    "                 dropout = 1, reject_cost = 0.2, activation=\"relu\",  reg = 0, dynamic = False, batch_norm=True, double=False):\n",
    "        self.double = double\n",
    "        self.new_loss = new_loss\n",
    "        self.network_name = network_name\n",
    "        self.num_forward_layers = num_forward_layers\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.batch_norm = batch_norm\n",
    "        self.input_shape = input_shape #FIXIT: assumption is images are square\n",
    "        self.dims = dims\n",
    "        self.padding = padding\n",
    "        self.learning_rate = learning_rate\n",
    "        self.pool_sizes = pool_sizes\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.num_classed = num_classes\n",
    "        self.dropout = dropout\n",
    "        self.dynamic = dynamic\n",
    "        self.num_classes = num_classes\n",
    "        self.path = path\n",
    "        self.cost_history = []\n",
    "        self.reg = reg\n",
    "        self.out_dict = {}\n",
    "        self.flatten_size = self.flatten_size_calculator()\n",
    "        self.Pdic = self.make_Pdic()\n",
    "        self.initialize = initialize\n",
    "        if double:\n",
    "            self.centers1, self.centers2 = centers\n",
    "        else:\n",
    "            self.centers = centers\n",
    "        self.input_ph = tf.placeholder(dtype= tf.float32, \n",
    "                                       shape= [None, self.input_shape[0],self.input_shape[1],self.input_shape[2]])\n",
    "        self.output_ph = tf.placeholder(dtype= tf.int32, \n",
    "                                        shape= [None,])\n",
    "        self.is_training_ph = tf.placeholder(tf.bool)\n",
    "        self.activation = self.get_activation(activation)\n",
    "        self.build(self.input_ph)\n",
    "        \n",
    "    def make_Pdic(self):\n",
    "        \n",
    "        Pdic = {}\n",
    "        \n",
    "        Pdic[\"W\"] = tf.get_variable(\"W\", shape = [self.hidden_sizes[self.num_forward_layers-1],self.num_classes],\n",
    "                                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Pdic[\"b\"] = tf.get_variable(\"b\", shape=[self.num_classes], initializer=tf.zeros_initializer())\n",
    "        \n",
    "        self.sum_weights = tf.reduce_sum( Pdic[\"W\"]**2)\n",
    "        \n",
    "        flat_length = self.flatten_size[self.num_conv_layers-1]\n",
    "        \n",
    "        for number in range(self.num_conv_layers):\n",
    "            Pdic[\"K{}\".format(number)] =  tf.get_variable(\"K{}\".format(number), \n",
    "                                                               shape=[self.kernel_sizes[number],self.kernel_sizes[number],\n",
    "                                                              (number==0)*self.input_shape[-1] + (number>0)*self.dims[number-1],\n",
    "                                                              self.dims[number]],initializer=tf.contrib.layers.xavier_initializer())\n",
    "            Pdic[\"z{}\".format(number)] = tf.get_variable(\"z{}\".format(number), shape = [self.dims[number]], \n",
    "                                                          initializer=tf.zeros_initializer())\n",
    "        \n",
    "        for layer in range(self.num_forward_layers):\n",
    "            \n",
    "            Pdic[\"W{}\".format(layer)] = tf.get_variable(\"W{}\".format(layer),\n",
    "                                                             shape=[flat_length*(layer==0)+self.hidden_sizes[layer-1]*(layer>0),\n",
    "                                                                    self.hidden_sizes[layer]],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            self.sum_weights += tf.reduce_sum( Pdic[\"W{}\".format(layer)]**2)\n",
    "            Pdic[\"b{}\".format(layer)] = tf.get_variable(\"b{}\".format(layer), \n",
    "                                                             shape=[self.hidden_sizes[layer]], initializer=tf.zeros_initializer())\n",
    "        return Pdic\n",
    "        \n",
    "\n",
    "    \n",
    "    def calculate_dic(self):\n",
    "        dic = {}\n",
    "        corrects = tf.cast(tf.equal(tf.cast(tf.argmax(self.out,1),tf.int32),self.output_ph),\"float\")\n",
    "        dic[\"accuracy\"] = tf.reduce_mean(corrects)  \n",
    "        return dic\n",
    "\n",
    "    def get_activation(self, name):\n",
    "        if name == \"relu\":\n",
    "            return tf.nn.relu\n",
    "        if name == \"tanh\":\n",
    "            return tf.nn.tanh\n",
    "        if name == \"sigmoid\":\n",
    "            return tf.sigmoid\n",
    "    \n",
    "    \n",
    "    def conv_layer(self, number, feed):\n",
    "        \n",
    "        conv = tf.nn.conv2d(input=feed, filter=self.Pdic[\"K{}\".format(number)], padding=\"SAME\", strides=[1,1,1,1])\n",
    "        out_convv = self.activation(conv + self.Pdic[\"z{}\".format(number)])\n",
    "        if self.batch_norm:\n",
    "            out_conv = tf.layers.batch_normalization(out_convv,axis=-1,training=self.is_training_ph)\n",
    "        else:\n",
    "            out_conv = out_convv\n",
    "        pool = tf.layers.max_pooling2d(inputs=out_conv, pool_size=self.pool_sizes[number], strides=self.pool_sizes[number])\n",
    "        return pool\n",
    "    \n",
    "    def fc_layer(self, layer, feed):\n",
    "        out = tf.matmul(feed,self.Pdic[\"W{}\".format(layer)])+self.Pdic[\"b{}\".format(layer)]\n",
    "        out_relued = tf.nn.dropout(self.activation(out), self.dropout)\n",
    "        return out_relued\n",
    "    \n",
    "    def flatten_size_calculator(self):\n",
    "        output = np.zeros(self.num_conv_layers)\n",
    "        temp = self.input_shape[0]//self.pool_sizes[0]\n",
    "        output[0] = temp*temp*self.dims[0]\n",
    "        for n in range(1,self.num_conv_layers):\n",
    "            temp = temp//self.pool_sizes[n]\n",
    "            output[n] = temp*temp*self.dims[n]\n",
    "        return output.astype(int)\n",
    "    \n",
    "        \n",
    "    def build(self, feed):\n",
    "        double = self.double\n",
    "        with tf.device('/gpu:1'):\n",
    "            if double:\n",
    "                centers1 = tf.cast(tf.constant(self.centers1),tf.float32)\n",
    "                centers2 = tf.cast(tf.constant(self.centers2),tf.float32)\n",
    "            else:\n",
    "                if self.dynamic:\n",
    "                    centers = tf.cast(tf.Variable(self.centers),tf.float32)\n",
    "\n",
    "                else:\n",
    "                    centers = tf.cast(tf.constant(self.centers),tf.float32)\n",
    "            # FIXIT: assumption is all convolutions are square\n",
    "            #_____________________Conv Layer0______________________________________________________________________________\n",
    "            if not self.double:\n",
    "                self.centers_var = centers\n",
    "            out = feed\n",
    "            for layer in range(self.num_conv_layers):\n",
    "                out = self.conv_layer(layer, out)\n",
    "\n",
    "            #_____________________Exit_____________________________________________________________________________________\n",
    "            flat_length = self.flatten_size[self.num_conv_layers-1]\n",
    "            out = tf.reshape(out, shape=[-1, flat_length])\n",
    "\n",
    "            for layer in range(self.num_forward_layers):\n",
    "                out = self.fc_layer(layer,out)\n",
    "\n",
    "            self.hidden = out\n",
    "            self.out = tf.matmul(self.hidden,self.Pdic[\"W\"])+self.Pdic[\"b\"]\n",
    "            self.dic = self.calculate_dic()\n",
    "            labels = tf.cast(tf.one_hot(self.output_ph,self.num_classes),tf.float32)\n",
    "            if double:\n",
    "                self.distances1 = tf_l2_distance(self.hidden,centers1)\n",
    "                self.distances2 = tf_l2_distance(self.hidden,centers2)  \n",
    "            else:\n",
    "                self.distances = tf_l2_distance(self.hidden,centers)\n",
    "            self.dic[\"cost\"] = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.out, labels=self.output_ph))\\\n",
    "            + 0.5*self.reg*(self.sum_weights)\n",
    "            if double:\n",
    "                \n",
    "                 self.dic[\"cost_h\"] =  tf.reduce_mean(tf.reduce_sum(tf.minimum(self.distances1, self.distances2)* \\\n",
    "                                                                   (labels-self.new_loss*(1-labels)),axis=1))\\\n",
    "                +0.5*self.reg*(self.sum_weights)\n",
    "            else:\n",
    "                \n",
    "                self.dic[\"cost_h\"] =  tf.reduce_mean(tf.reduce_sum(self.distances * \\\n",
    "                                                                   (labels-self.new_loss*(1-labels)),axis=1))\\\n",
    "                +0.5*self.reg*(self.sum_weights)\n",
    "\n",
    "            \n",
    "            \n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops):                                                                       \n",
    "                self.dic[\"optmz_h\"]= tf.train.AdamOptimizer(self.learning_rate).minimize(self.dic[\"cost_h\"])\n",
    "                self.dic[\"optmz\"]= tf.train.AdamOptimizer(self.learning_rate).minimize(self.dic[\"cost\"])\n",
    "        if self.initialize:\n",
    "            saver = tf.train.Saver()\n",
    "            init = tf.global_variables_initializer() \n",
    "            sess = get_session()\n",
    "            sess.run(init)\n",
    "            saver.save(sess,self.path)\n",
    "        \n",
    "\n",
    "    \n",
    "    def get_batches(self, training_data, batch_size, validation_data):   \n",
    "        Xs = training_data[0]\n",
    "        Ys = training_data[1]\n",
    "        mask = np.random.permutation(len(Ys))\n",
    "        Xs = Xs[mask]\n",
    "        Ys = Ys[mask]\n",
    "        X_batches = [Xs[k:k + batch_size] for k in range(0, len(Xs), batch_size)]\n",
    "        Y_batches = [Ys[k:k + batch_size] for k in range(0, len(Ys), batch_size)]\n",
    "        return X_batches, Y_batches, validation_data[0], validation_data[1]\n",
    "\n",
    "\n",
    "    def do_epoch(self, sess, epoch, X_batches, Y_batches, X_val, Y_val, clustering, X_train, Y_train, verbose):\n",
    "        avg_cost = 0\n",
    "        mskn = np.random.choice(range(X_train.shape[0]),1000)\n",
    "        x_train = X_train[mskn]\n",
    "        y_train = Y_train[mskn]\n",
    "        for X_batch, Y_batch in zip(X_batches, Y_batches):\n",
    "            if clustering:\n",
    "                _, c = sess.run([self.dic[\"optmz_h\"], self.dic[\"cost_h\"]], \n",
    "                                feed_dict={self.input_ph:X_batch, self.output_ph:Y_batch, self.is_training_ph:True})\n",
    "                avg_cost += c/len(X_batch)\n",
    "            else:\n",
    "                _, c = sess.run([self.dic[\"optmz\"], self.dic[\"cost\"]], \n",
    "                                feed_dict={self.input_ph:X_batch, self.output_ph:Y_batch, self.is_training_ph:True})\n",
    "                avg_cost += c/len(X_batch)\n",
    "        self.cost_history.append(avg_cost)    \n",
    "        if clustering:\n",
    "            if not self.double:\n",
    "                self.centers = sess.run(self.centers_var) #FIXIT\n",
    "            val_h = sess.run(self.hidden,  feed_dict={self.input_ph:X_val, self.is_training_ph:False})\n",
    "            acc, rate = self.evaluate(val_h,Y_val)\n",
    "            tr_h = sess.run(self.hidden,  feed_dict={self.input_ph:x_train, self.is_training_ph:False})\n",
    "            acc_train, _ = self.evaluate(tr_h,y_train)\n",
    "            if verbose:\n",
    "                print(\"epoch:{},validation accuracy:{},training accuracy:{},rate:{},cost:{}\".format(epoch,acc,acc_train,rate,avg_cost))\n",
    "        else:\n",
    "            acc = sess.run(self.dic[\"accuracy\"], \n",
    "                           feed_dict={self.input_ph:X_val, self.output_ph:Y_val, self.is_training_ph:False})\n",
    "            acc_train = sess.run(self.dic[\"accuracy\"],\n",
    "                                 feed_dict={self.input_ph:x_train, self.output_ph:y_train, self.is_training_ph:False})\n",
    "            if verbose:\n",
    "                print(\"Epoch:{},acc:{},acc_train:{},cost:{}\".format(epoch,acc,acc_train,avg_cost))\n",
    "        \n",
    "        return acc\n",
    "    \n",
    "    def tradeoff(self,sess, X_val, Y_val, clustering):\n",
    "        self.acc_hist = []\n",
    "        self.rate_hist = []\n",
    "        self.thresh_list = []\n",
    "        if clustering:\n",
    "            val_h = sess.run(self.hidden,  feed_dict={self.input_ph:X_val, self.is_training_ph:False})\n",
    "            r=0.\n",
    "            thresh = 1e5*1.\n",
    "            while(r<0.95):\n",
    "                thresh /= 1.001\n",
    "                self.thresh_list.append(thresh)\n",
    "                a,r = self.evaluate(val_h,Y_val,thresh)\n",
    "                r = 1-r\n",
    "                self.acc_hist.append(a)\n",
    "                self.rate_hist.append(r)\n",
    "#                 print(thresh,a,r)\n",
    "        else:\n",
    "            val = sess.run(tf.nn.softmax(self.out),  feed_dict={self.input_ph:X_val, self.is_training_ph:False})\n",
    "            ent = entropy(val)\n",
    "            r = 0.\n",
    "            thresh = 10.\n",
    "            while(r<.95):\n",
    "                thresh /= 1.01\n",
    "                self.thresh_list.append(thresh)\n",
    "                passes = (ent<thresh).astype(float)\n",
    "                corrects = (np.argmax(val,1)==Y_val).astype(float) * passes\n",
    "                a = np.sum(corrects)/np.sum(passes)\n",
    "                r = 1-np.sum(passes)/val.shape[0]\n",
    "                self.acc_hist.append(a)\n",
    "                self.rate_hist.append(r)\n",
    "#                 print(thresh,a,r)\n",
    "        \n",
    "    def optimize(self, clustering, training_data, validation_data, save, load , reg= 0, epochs=10,\n",
    "                 batch_size= 200, tradeoff=False, verbose=True, save_always=False):\n",
    "        X_batches, Y_batches, X_val, Y_val = self.get_batches(training_data, batch_size, validation_data)\n",
    "        X_train = training_data[0]\n",
    "        Y_train = training_data[1]\n",
    "        saver = tf.train.Saver()\n",
    "        init = tf.global_variables_initializer() \n",
    "\n",
    "        with tf.Session(config=config_gpu) as sess:\n",
    "            sess.run(init)\n",
    "            best_val = 0.\n",
    "            \n",
    "            if load:\n",
    "                if verbose:\n",
    "                    print(\"Loading model from :{}\".format(self.path))\n",
    "                saver.restore(sess,self.path)\n",
    "\n",
    "            if clustering:\n",
    "                val_h = sess.run(self.hidden,  feed_dict={self.input_ph:X_val, self.is_training_ph:False})\n",
    "                best_val, _ = self.evaluate(val_h,Y_val)\n",
    "                if verbose:\n",
    "                    print(\"validation accuracy before starting\",best_val)\n",
    "            else:\n",
    "                best_val = sess.run(self.dic[\"accuracy\"], \n",
    "                                    feed_dict={self.input_ph:X_val, self.output_ph:Y_val, self.is_training_ph:False})\n",
    "                if verbose:\n",
    "                    print(\"validation accuracy before starting\",best_val)\n",
    "                \n",
    "            for epoch in range(epochs):\n",
    "                acc = self.do_epoch(sess, epoch, X_batches, Y_batches, X_val, Y_val, clustering, X_train, Y_train, verbose)\n",
    "                if acc>=best_val or save_always: #FIXIT\n",
    "                    best_val = acc\n",
    "                    saved_path = saver.save(sess, self.path)\n",
    "                    if verbose:\n",
    "                        print(\"New best!\")\n",
    "            self.best_val = best_val \n",
    "            print(\"Best val accuracy:\",self.best_val)\n",
    "            saver.restore(sess,self.path)\n",
    "            if tradeoff:\n",
    "                self.tradeoff(sess, X_val, Y_val, clustering)\n",
    "\n",
    "    def tf_PolMut(self, x, eta=15., prob=0.1,up=255.0,down=0.):\n",
    "        up = up*1.\n",
    "        down = down*1.\n",
    "        eta = eta*1.\n",
    "        mask = tf.cast(tf.less(tf.random_uniform(tf.shape(x),0,1),prob),tf.float32)\n",
    "        changed = mask*x\n",
    "        unchanged = (1-mask)*x\n",
    "        delta1 = x*mask/(up-down)\n",
    "        delta2 = (1-x)*mask/(up-down)\n",
    "        r = tf.cast(tf.random_uniform(tf.shape(x),0,1),tf.float32)\n",
    "        r_mask = tf.cast(tf.less(r,0.5),tf.float32)\n",
    "        r_mask1 = r_mask * mask\n",
    "        r_mask2 = (1-r_mask) * mask\n",
    "        r1 = r * r_mask1\n",
    "        r2 = r * r_mask2\n",
    "        q1 = (2*r1+(1-2*r1)*r_mask1*(mask*(1-delta1))**(eta+1))\n",
    "        q2 = (2*(1-r2)+2*(r2-0.5)*r_mask2*(mask*(1-delta2))**(eta+1))\n",
    "        d = (q1**(1./(eta+1))-1) * r_mask1 + (1-q2**(1./(eta+1))) * r_mask2\n",
    "        result = unchanged + changed+d*(up-down)\n",
    "        return result\n",
    "    \n",
    "    def PM(self, clustering, num_pic, num_iter, num_sample):\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session(config=config_gpu) as sess:\n",
    "            saver.restore(sess,self.path)\n",
    "            best_pic = np.zeros((10*num_pic,32,32,3))\n",
    "            best_score = 1e100*np.ones(10*num_pic)*1.\n",
    "            \n",
    "            for ctr in range(num_pic):\n",
    "                x = 255*np.random.random((num_sample,32,32,3))    \n",
    "                print(ctr)\n",
    "                for i in range(num_iter):\n",
    "                    if clustering:\n",
    "                        hidden = sess.run(self.hidden, {self.input_ph: x-mean_image, self.is_training_ph: False})\n",
    "                        out = l2_distance(hidden,self.centers)\n",
    "                        min_index = out.argmin(axis=0)\n",
    "                        for cls in range(10):\n",
    "                            if out[min_index[cls]][cls]<best_score[cls*num_pic+ctr]:\n",
    "                                best_score[cls*num_pic+ctr] = out[min_index[cls]][cls]\n",
    "                                best_pic[cls*num_pic+ctr] = x[min_index[cls]]-mean_image\n",
    "                    else:\n",
    "                        out = sess.run(tf.nn.softmax(self.out), {self.input_ph: x-mean_image, self.is_training_ph: False})\n",
    "                        max_index = out.argmax(axis=0)\n",
    "                        for cls in range(10):\n",
    "                            if out[max_index[cls]][cls]>best_score[cls*num_pic+ctr]:\n",
    "                                best_score[cls*num_pic+ctr] = out[max_index[cls]][cls]\n",
    "                                best_pic[cls*num_pic+ctr] = x[max_index[cls]]-mean_image\n",
    "                    x = sess.run(self.tf_PolMut(tf.constant(x,dtype=tf.float32),15,.1,255.,0.))\n",
    "        return best_pic, best_score\n",
    "    \n",
    "    def hist_dist(self,x,y):\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session(config=config_gpu) as sess:\n",
    "            saver.restore(sess,self.path)\n",
    "            if self.double:\n",
    "                distances1 = sess.run(self.distances1, {self.input_ph: x, self.output_ph:y, self.is_training_ph : False})\n",
    "                distances2 = sess.run(self.distances2, {self.input_ph: x, self.output_ph:y, self.is_training_ph : False})\n",
    "                distances = np.minimum(distances1,distances2)\n",
    "            else:\n",
    "                distances = sess.run(self.distances, {self.input_ph: x, self.output_ph:y, self.is_training_ph : False})\n",
    "            output1 = distances[np.arange(y.shape[0]),y]\n",
    "            return output1,distances\n",
    "        \n",
    "    def predict(self, hidden):\n",
    "        index = -1\n",
    "        counter = 0.\n",
    "        correct = 0.\n",
    "        out = np.zeros(hidden.shape[0])\n",
    "        if self.double:\n",
    "            diff = np.min()\n",
    "        else:\n",
    "            diff = l2_distance(hidden,self.centers)\n",
    "        out = np.argmin(diff,axis=1)\n",
    "        return out\n",
    "    \n",
    "    def evaluate(self, hidden, y, thresh=1e100):\n",
    "        correct = 0.\n",
    "        if self.double:\n",
    "            diff1 = l2_distance(hidden,self.centers1)\n",
    "            diff2 = l2_distance(hidden,self.centers2)\n",
    "            diff = np.minimum(diff1,diff2)\n",
    "        else:\n",
    "            diff = l2_distance(hidden,self.centers)\n",
    "            \n",
    "        passed = np.min(diff,1)<thresh\n",
    "        passed_num = np.sum(passed)\n",
    "        correct = np.argmin(diff,1) == y     \n",
    "        return np.sum(correct*passed)*1./passed_num, passed_num*1./y.shape[0]\n",
    "            \n",
    "    \n",
    "    def feedforward(self, feed, sess=None):\n",
    "        if sess==None:\n",
    "            sess=get_session()\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess,self.path)            \n",
    "        output = sess.run(tf.nn.softmax(self.out), {self.input_ph: feed, self.is_training_ph : False})\n",
    "        return output\n",
    "    \n",
    "    def scores(self, feed, sess=None):\n",
    "        if sess==None:\n",
    "            sess=get_session()\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess,self.path)  \n",
    "        output = sess.run(self.hidden, {self.input_ph: feed, self.is_training_ph : False})\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from :../../../../../lfs/1/amiratag/saved_models/1C_3L_F\n",
      "('validation accuracy before starting', 0.79300004)\n",
      "Epoch:0,acc:0.790000081062,acc_train:1.00000011921,cost:0.0477985585108\n",
      "('Best val accuracy:', 0.79300004)\n"
     ]
    }
   ],
   "source": [
    "clustering = False\n",
    "best_val = 0.\n",
    "learning_rate = [1e-3]\n",
    "regularization = [0]\n",
    "dropout = [1]\n",
    "best_val=0\n",
    "tf.reset_default_graph()\n",
    "network3 = CNN_SC(centers = np.random.random((10,1024)),new_loss=0, network_name=\"network1\", num_conv_layers=3, \n",
    "                   num_forward_layers=1,\n",
    "                  input_shape=[32,32,3], reg = 1e-2,num_classes=10, kernel_sizes=[5,5,5], hidden_sizes=[1024], \n",
    "                  pool_sizes=[2,2,2], padding = \"same\", path ='../../../../../lfs/1/amiratag/saved_models/1C_3L_F',\n",
    "                  dims=[64,128,256], learning_rate = 1e-3, batch_norm = True, dropout = 1)\n",
    "network3.optimize(clustering, training_data, validation_data1, epochs=1, load = True, save = True, verbose=True)\n",
    "\n",
    "a = tf.constant(X_val[3000:5000])\n",
    "sess = tf.Session(config=config_gpu)\n",
    "val_reshaped = tf.reshape(a,[-1,32*32*3])\n",
    "dist_train = np.zeros((2000,40000))\n",
    "for i in range(40):\n",
    "    dist_train[:,i*1000:(i+1)*1000] = \\\n",
    "    sess.run(tf_l2_distance(val_reshaped,tf.reshape(tf.constant(X_train[i*1000:(i+1)*1000])\n",
    "                                                    ,[-1,32*32*3])))\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess,network3.path) \n",
    "train_mapped = np.zeros((40000,1024))\n",
    "val_mapped = np.zeros((2000,1024))\n",
    "dist_score_space = np.zeros((2000,40000))\n",
    "for i in range(40):\n",
    "    train_mapped[i*1000:(i+1)*1000] = network3.scores(X_train[i*1000:(i+1)*1000],sess)\n",
    "val_mapped = network3.scores(X_val[3000:5000],sess)\n",
    "for i in range(40):\n",
    "    dist_score_space[:,i*1000:(i+1)*1000] =\\\n",
    "    sess.run(tf_l2_distance(tf.constant(val_mapped),\n",
    "                            tf.cast(tf.constant(train_mapped[i*1000:(i+1)*1000]),tf.float32)))\n",
    "\n",
    "args_train = np.argsort(dist_train,1) \n",
    "sorted_train = np.sort(dist_train,1)\n",
    "args_score =np.argsort(dist_score_space,1) \n",
    "sorted_score = np.sort(dist_score_space,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_train=np.zeros((2000,2000))\n",
    "memory_score=np.zeros((2000,2000))\n",
    "for n in range(1,2001):\n",
    "    for i in range(2000):\n",
    "        memory_train[n-1,i] = np.sum(y_train[args_train[i,:n]]==y_val[3000+i])*1./n\n",
    "        memory_score[n-1,i] = np.sum(y_train[args_score[i,:n]]==y_val[3000+i])*1./n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAFHCAYAAAAV5w+DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwrzHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0bbc6d0a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 5, 5\n",
    "rcParams.update({'font.size': 10})\n",
    "plt.plot(range(1,2001),100*np.mean(memory_train,1),range(1,2001),\n",
    "         100*np.mean(memory_score,1),linewidth=6)\n",
    "plt.legend([\"Original Space\",\"Score Space\"])\n",
    "plt.xlabel(\"n (number of nearest neighbors in the training set)\")\n",
    "plt.ylabel(\"% of neighbors in the same class\")\n",
    "plt.xticks([0,200,400,600,800,1000,1200,1400,1600,1800,2000])\n",
    "plt.yticks([0,10,20,30,40,50,60,70,80,90,100])\n",
    "plt.axis([0,2000,0,100])\n",
    "plt.grid(color=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12917414999999999"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gooz=np.zeros(2000)\n",
    "n=10000\n",
    "for i in range(2000):\n",
    "    gooz[i]=np.sum(y_train[args_train[i,:n]]==y_val[3000+i])*1./n\n",
    "np.mean(gooz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
